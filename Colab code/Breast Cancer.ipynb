{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Breast Cancer.ipynb","provenance":[],"authorship_tag":"ABX9TyNbkZJ+/3l5fLVYr6EpGFZW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I1xWl7a6CyDJ","executionInfo":{"status":"ok","timestamp":1626273574330,"user_tz":-330,"elapsed":981,"user":{"displayName":"Pranab Nandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGLcljhGoE0GLEMDmePj-4a2kCmrEAFJ1MRjpqqQ=s64","userId":"14510125254852299567"}},"outputId":"7f76830d-ca4c-40f9-b03d-40b1b1a0937b"},"source":["\n","from skimage import io,color\n","from skimage.transform import resize\n","import numpy as np\n","from keras import layers\n","from keras.layers import Input, Add, Dense,Dropout,Concatenate, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n","from keras.models import Model, load_model     # load_model is used to load the saved model\n","from keras.initializers import glorot_uniform  # it initialises the weights according to some distribution\n","from keras.optimizers import *\n","from matplotlib import pyplot as plt\n","from numpy import array\n","from matplotlib.pyplot import imshow\n","import keras.backend as K\n","import json\n","K.set_image_data_format('channels_last')\n","K.set_learning_phase(1)   \n","from keras.preprocessing.image import ImageDataGenerator    # ImageDataGenerator is used for handling bunches of images. It reads the images from folders and also labels them like as 0 for benign, 1 for insitu, 2 for invasive, 3 for normal\n","bn='bn_layer_'\n","conv='conv_layer_'\n","fc= 'fc_layer_'\n","k=32      # here k = no of channels at each layer"],"execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"T5ZWhvsODATq","executionInfo":{"status":"ok","timestamp":1626273576238,"user_tz":-330,"elapsed":7,"user":{"displayName":"Pranab Nandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGLcljhGoE0GLEMDmePj-4a2kCmrEAFJ1MRjpqqQ=s64","userId":"14510125254852299567"}}},"source":["def save_history(history,file):\n","    with open(file, 'w') as f:\n","        json.dump(history, f)\n","    '''\n","    data = dict()\n","    with open('mydatafile') as f:\n","        data = json.load(f)\n","    '''"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"gvbxAe7rDpoh","executionInfo":{"status":"ok","timestamp":1626273578499,"user_tz":-330,"elapsed":8,"user":{"displayName":"Pranab Nandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGLcljhGoE0GLEMDmePj-4a2kCmrEAFJ1MRjpqqQ=s64","userId":"14510125254852299567"}}},"source":["def bottleneck_composite(l,layer):   # everytime we call this function we create two layers\n","    # bottleneck layer\n","    X=l\n","    if type(l) is list:\n","        if(len(l)==1):\n","            X=l[0]\n","        else:\n","            X=Concatenate(axis=-1)(l)   # for channel-wise concatenation like if we have two 20x20 images to concatenate then by doing axis=-1 we want the result to be (20, 20, 2) and not (20,40)\n","\n","    X = BatchNormalization(axis = 3, name = bn + str(layer))(X)\n","    X = Activation('relu')(X)\n","    X = Conv2D(4*k, (1, 1), strides = (1, 1),padding='same', name = conv + str(layer), kernel_initializer = glorot_uniform(seed=0))(X)  # to limit each layer input channel size to 4*k\n","    X = Dropout(0.8)(X)\n","    # Composite layer\n","    layer=layer+1\n","    X = BatchNormalization(axis = 3, name = bn +  str(layer))(X)\n","    X = Activation('relu')(X)\n","    X = Conv2D(k, (3, 3), strides = (1, 1),padding='same', name = conv +  str(layer), kernel_initializer = glorot_uniform(seed=0))(X)\n","    X = Dropout(0.8)(X)\n","    return X\n","    \n","    "],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"illB7lxCDu-A","executionInfo":{"status":"ok","timestamp":1626273580395,"user_tz":-330,"elapsed":7,"user":{"displayName":"Pranab Nandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGLcljhGoE0GLEMDmePj-4a2kCmrEAFJ1MRjpqqQ=s64","userId":"14510125254852299567"}}},"source":["layer=0    \n","def denseNet(classes=4,input_shape=(224,224,3)):\n","    X_input = Input(input_shape)   # X_input is a 4-D tensor (None, 224, 224, 3) where None would be replaced by batch size.\n","    layer=0\n","    layer=layer+1\n","    X = ZeroPadding2D((3, 3))(X_input)  # ZeroPadding2D is a function of the form ZeroPadding2D(( , ))(X) which pads onto the given array X\n","    X = BatchNormalization(axis = 3, name = bn + str(layer))(X)   # axis=3 indicates we batchnormalise channel-wise by doing (x-mean)/sd or something similar\n","    X = Activation('relu')(X)\n","    X = Conv2D(2*k, (7, 7), strides = (2, 2), name = conv + str(layer), kernel_initializer = glorot_uniform(seed=0))(X)  # 2*k is the no of filters/kernels, 7x7 is the kernel/filter size and seed=0 ensures consistency in results \n","    X = Dropout(0.8)(X)    # 80% dropout\n","    print(X.shape)\n","    X = ZeroPadding2D((1, 1))(X)\n","    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n","    print(X.shape)\n","\n","    #Dense Block = 1\n","    layer=layer+1\n","    X=bottleneck_composite(X,layer)\n","    l=[]\n","    l.append(X)\n","    for i in range(0,5):\n","        layer=layer+2         # we increment layer by 2 because each time we bottleneck_composite() we created two layers\n","        X=bottleneck_composite(l,layer)\n","        l.append(X)\n","    print(X.shape)\n","\n","    # Transition layer = 1   \n","    layer=layer+2\n","    X = BatchNormalization(axis = 3, name = bn +  str(layer))(X)\n","    X = Activation('relu')(X)\n","    X = Conv2D(k, (1, 1), strides = (1, 1),padding ='same', name = conv +  str(layer), kernel_initializer = glorot_uniform(seed=0))(X)\n","    X = Dropout(0.8)(X)\n","    X = AveragePooling2D((2, 2), strides=(2, 2))(X)  \n","    print(X.shape)\n","    \n","    #Dense Block = 2\n","    layer=layer+1\n","    X=bottleneck_composite(X,layer)\n","    l=[]\n","    l.append(X)\n","    for i in range(0,11):\n","        layer=layer+2\n","        X=bottleneck_composite(l,layer)\n","        l.append(X)\n","    \n","    print(X.shape)\n","\n","    # Transition layer = 2\n","    layer=layer+2\n","    X = BatchNormalization(axis = 3, name = bn +  str(layer))(X)\n","    X = Activation('relu')(X)\n","    X = Conv2D(k, (1, 1), strides = (1, 1),padding ='same', name = conv +  str(layer), kernel_initializer = glorot_uniform(seed=0))(X)\n","    X = Dropout(0.8)(X)\n","    X = AveragePooling2D((2, 2), strides=(2, 2))(X)  \n","    print(X.shape)\n","\n","    #Dense Block = 3\n","    layer=layer+1\n","    X=bottleneck_composite(X,layer)\n","    l=[]\n","    l.append(X)\n","    for i in range(0,23):\n","        layer=layer+2\n","        X=bottleneck_composite(l,layer)\n","        l.append(X)\n","    print(X.shape)\n","\n","    # Transition layer = 3\n","    layer=layer+2\n","    X = BatchNormalization(axis = 3, name = bn +  str(layer))(X)\n","    X = Activation('relu')(X)\n","    X = Conv2D(k, (1, 1), strides = (1, 1),padding ='same', name = conv +  str(layer), kernel_initializer = glorot_uniform(seed=0))(X)\n","    X = Dropout(0.8)(X)\n","    X = AveragePooling2D((2, 2), strides=(2, 2))(X)  \n","    print(X.shape)\n","\n","    #Dense Block = 4\n","    layer=layer+1\n","    X=bottleneck_composite(X,layer)\n","    l=[]\n","    l.append(X)\n","    for i in range(0,15):\n","        layer=layer+2\n","        X=bottleneck_composite(l,layer)\n","        l.append(X)\n","    print(X.shape)\n","    layer=layer+2\n","    print(X.shape)\n","\n","    X=  GlobalAveragePooling2D()(X)  # it works for each channel so if we have 32 channels we have 32 outputs\n","    print(X.shape)\n","   \n","    X = Dense(classes, activation='softmax', name=  fc  +  str(layer), kernel_initializer = glorot_uniform(seed=0))(X)  # output layer\n","    print(X.shape)\n","    model = Model(inputs = X_input, outputs = X, name=\"DenseNet121\")   # this line builds the entire architecture pipeline\n","    \n","    return model\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hzvMMDFWDzK1","executionInfo":{"status":"ok","timestamp":1626273585879,"user_tz":-330,"elapsed":3322,"user":{"displayName":"Pranab Nandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGLcljhGoE0GLEMDmePj-4a2kCmrEAFJ1MRjpqqQ=s64","userId":"14510125254852299567"}},"outputId":"1175e772-8d16-41b7-8b8a-499a6cbff1a2"},"source":["\n","adam=Adam(lr=0.001)   # we start with a random learning rate\n","model = denseNet(classes = 4,input_shape = (224,224,3))\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])    \n","#model.summary()\n","train_datagen = ImageDataGenerator( rescale=1./255)    \n","val_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen=ImageDataGenerator(rescale=1./255)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["(None, 112, 112, 64)\n","(None, 56, 56, 64)\n","(None, 56, 56, 32)\n","(None, 28, 28, 32)\n","(None, 28, 28, 32)\n","(None, 14, 14, 32)\n","(None, 14, 14, 32)\n","(None, 7, 7, 32)\n","(None, 7, 7, 32)\n","(None, 7, 7, 32)\n","(None, 32)\n","(None, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkAJ-CKxD234","executionInfo":{"status":"ok","timestamp":1626267044742,"user_tz":-330,"elapsed":798,"user":{"displayName":"Pranab Nandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGLcljhGoE0GLEMDmePj-4a2kCmrEAFJ1MRjpqqQ=s64","userId":"14510125254852299567"}},"outputId":"fd0c45b6-f039-4e26-92df-16b7b301c3ac"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"DenseNet121\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d_4 (ZeroPadding2D (None, 230, 230, 3)  0           input_3[0][0]                    \n","__________________________________________________________________________________________________\n","bn_layer_1 (BatchNormalization) (None, 230, 230, 3)  12          zero_padding2d_4[0][0]           \n","__________________________________________________________________________________________________\n","activation_240 (Activation)     (None, 230, 230, 3)  0           bn_layer_1[0][0]                 \n","__________________________________________________________________________________________________\n","conv_layer_1 (Conv2D)           (None, 112, 112, 64) 9472        activation_240[0][0]             \n","__________________________________________________________________________________________________\n","dropout_240 (Dropout)           (None, 112, 112, 64) 0           conv_layer_1[0][0]               \n","__________________________________________________________________________________________________\n","zero_padding2d_5 (ZeroPadding2D (None, 114, 114, 64) 0           dropout_240[0][0]                \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           zero_padding2d_5[0][0]           \n","__________________________________________________________________________________________________\n","bn_layer_2 (BatchNormalization) (None, 56, 56, 64)   256         max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","activation_241 (Activation)     (None, 56, 56, 64)   0           bn_layer_2[0][0]                 \n","__________________________________________________________________________________________________\n","conv_layer_2 (Conv2D)           (None, 56, 56, 128)  8320        activation_241[0][0]             \n","__________________________________________________________________________________________________\n","dropout_241 (Dropout)           (None, 56, 56, 128)  0           conv_layer_2[0][0]               \n","__________________________________________________________________________________________________\n","bn_layer_3 (BatchNormalization) (None, 56, 56, 128)  512         dropout_241[0][0]                \n","__________________________________________________________________________________________________\n","activation_242 (Activation)     (None, 56, 56, 128)  0           bn_layer_3[0][0]                 \n","__________________________________________________________________________________________________\n","conv_layer_3 (Conv2D)           (None, 56, 56, 32)   36896       activation_242[0][0]             \n","__________________________________________________________________________________________________\n","dropout_242 (Dropout)           (None, 56, 56, 32)   0           conv_layer_3[0][0]               \n","__________________________________________________________________________________________________\n","bn_layer_4 (BatchNormalization) (None, 56, 56, 32)   128         dropout_242[0][0]                \n","__________________________________________________________________________________________________\n","activation_243 (Activation)     (None, 56, 56, 32)   0           bn_layer_4[0][0]                 \n","__________________________________________________________________________________________________\n","conv_layer_4 (Conv2D)           (None, 56, 56, 128)  4224        activation_243[0][0]             \n","__________________________________________________________________________________________________\n","dropout_243 (Dropout)           (None, 56, 56, 128)  0           conv_layer_4[0][0]               \n","__________________________________________________________________________________________________\n","bn_layer_5 (BatchNormalization) (None, 56, 56, 128)  512         dropout_243[0][0]                \n","__________________________________________________________________________________________________\n","activation_244 (Activation)     (None, 56, 56, 128)  0           bn_layer_5[0][0]                 \n","__________________________________________________________________________________________________\n","conv_layer_5 (Conv2D)           (None, 56, 56, 32)   36896       activation_244[0][0]             \n","__________________________________________________________________________________________________\n","dropout_244 (Dropout)           (None, 56, 56, 32)   0           conv_layer_5[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_100 (Concatenate)   (None, 56, 56, 64)   0           dropout_242[0][0]                \n","                                                                 dropout_244[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_6 (BatchNormalization) (None, 56, 56, 64)   256         concatenate_100[0][0]            \n","__________________________________________________________________________________________________\n","activation_245 (Activation)     (None, 56, 56, 64)   0           bn_layer_6[0][0]                 \n","__________________________________________________________________________________________________\n","conv_layer_6 (Conv2D)           (None, 56, 56, 128)  8320        activation_245[0][0]             \n","__________________________________________________________________________________________________\n","dropout_245 (Dropout)           (None, 56, 56, 128)  0           conv_layer_6[0][0]               \n","__________________________________________________________________________________________________\n","bn_layer_7 (BatchNormalization) (None, 56, 56, 128)  512         dropout_245[0][0]                \n","__________________________________________________________________________________________________\n","activation_246 (Activation)     (None, 56, 56, 128)  0           bn_layer_7[0][0]                 \n","__________________________________________________________________________________________________\n","conv_layer_7 (Conv2D)           (None, 56, 56, 32)   36896       activation_246[0][0]             \n","__________________________________________________________________________________________________\n","dropout_246 (Dropout)           (None, 56, 56, 32)   0           conv_layer_7[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_101 (Concatenate)   (None, 56, 56, 96)   0           dropout_242[0][0]                \n","                                                                 dropout_244[0][0]                \n","                                                                 dropout_246[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_8 (BatchNormalization) (None, 56, 56, 96)   384         concatenate_101[0][0]            \n","__________________________________________________________________________________________________\n","activation_247 (Activation)     (None, 56, 56, 96)   0           bn_layer_8[0][0]                 \n","__________________________________________________________________________________________________\n","conv_layer_8 (Conv2D)           (None, 56, 56, 128)  12416       activation_247[0][0]             \n","__________________________________________________________________________________________________\n","dropout_247 (Dropout)           (None, 56, 56, 128)  0           conv_layer_8[0][0]               \n","__________________________________________________________________________________________________\n","bn_layer_9 (BatchNormalization) (None, 56, 56, 128)  512         dropout_247[0][0]                \n","__________________________________________________________________________________________________\n","activation_248 (Activation)     (None, 56, 56, 128)  0           bn_layer_9[0][0]                 \n","__________________________________________________________________________________________________\n","conv_layer_9 (Conv2D)           (None, 56, 56, 32)   36896       activation_248[0][0]             \n","__________________________________________________________________________________________________\n","dropout_248 (Dropout)           (None, 56, 56, 32)   0           conv_layer_9[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_102 (Concatenate)   (None, 56, 56, 128)  0           dropout_242[0][0]                \n","                                                                 dropout_244[0][0]                \n","                                                                 dropout_246[0][0]                \n","                                                                 dropout_248[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_10 (BatchNormalization (None, 56, 56, 128)  512         concatenate_102[0][0]            \n","__________________________________________________________________________________________________\n","activation_249 (Activation)     (None, 56, 56, 128)  0           bn_layer_10[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_10 (Conv2D)          (None, 56, 56, 128)  16512       activation_249[0][0]             \n","__________________________________________________________________________________________________\n","dropout_249 (Dropout)           (None, 56, 56, 128)  0           conv_layer_10[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_11 (BatchNormalization (None, 56, 56, 128)  512         dropout_249[0][0]                \n","__________________________________________________________________________________________________\n","activation_250 (Activation)     (None, 56, 56, 128)  0           bn_layer_11[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_11 (Conv2D)          (None, 56, 56, 32)   36896       activation_250[0][0]             \n","__________________________________________________________________________________________________\n","dropout_250 (Dropout)           (None, 56, 56, 32)   0           conv_layer_11[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_103 (Concatenate)   (None, 56, 56, 160)  0           dropout_242[0][0]                \n","                                                                 dropout_244[0][0]                \n","                                                                 dropout_246[0][0]                \n","                                                                 dropout_248[0][0]                \n","                                                                 dropout_250[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_12 (BatchNormalization (None, 56, 56, 160)  640         concatenate_103[0][0]            \n","__________________________________________________________________________________________________\n","activation_251 (Activation)     (None, 56, 56, 160)  0           bn_layer_12[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_12 (Conv2D)          (None, 56, 56, 128)  20608       activation_251[0][0]             \n","__________________________________________________________________________________________________\n","dropout_251 (Dropout)           (None, 56, 56, 128)  0           conv_layer_12[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_13 (BatchNormalization (None, 56, 56, 128)  512         dropout_251[0][0]                \n","__________________________________________________________________________________________________\n","activation_252 (Activation)     (None, 56, 56, 128)  0           bn_layer_13[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_13 (Conv2D)          (None, 56, 56, 32)   36896       activation_252[0][0]             \n","__________________________________________________________________________________________________\n","dropout_252 (Dropout)           (None, 56, 56, 32)   0           conv_layer_13[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_14 (BatchNormalization (None, 56, 56, 32)   128         dropout_252[0][0]                \n","__________________________________________________________________________________________________\n","activation_253 (Activation)     (None, 56, 56, 32)   0           bn_layer_14[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_14 (Conv2D)          (None, 56, 56, 32)   1056        activation_253[0][0]             \n","__________________________________________________________________________________________________\n","dropout_253 (Dropout)           (None, 56, 56, 32)   0           conv_layer_14[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_6 (AveragePoo (None, 28, 28, 32)   0           dropout_253[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_15 (BatchNormalization (None, 28, 28, 32)   128         average_pooling2d_6[0][0]        \n","__________________________________________________________________________________________________\n","activation_254 (Activation)     (None, 28, 28, 32)   0           bn_layer_15[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_15 (Conv2D)          (None, 28, 28, 128)  4224        activation_254[0][0]             \n","__________________________________________________________________________________________________\n","dropout_254 (Dropout)           (None, 28, 28, 128)  0           conv_layer_15[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_16 (BatchNormalization (None, 28, 28, 128)  512         dropout_254[0][0]                \n","__________________________________________________________________________________________________\n","activation_255 (Activation)     (None, 28, 28, 128)  0           bn_layer_16[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_16 (Conv2D)          (None, 28, 28, 32)   36896       activation_255[0][0]             \n","__________________________________________________________________________________________________\n","dropout_255 (Dropout)           (None, 28, 28, 32)   0           conv_layer_16[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_17 (BatchNormalization (None, 28, 28, 32)   128         dropout_255[0][0]                \n","__________________________________________________________________________________________________\n","activation_256 (Activation)     (None, 28, 28, 32)   0           bn_layer_17[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_17 (Conv2D)          (None, 28, 28, 128)  4224        activation_256[0][0]             \n","__________________________________________________________________________________________________\n","dropout_256 (Dropout)           (None, 28, 28, 128)  0           conv_layer_17[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_18 (BatchNormalization (None, 28, 28, 128)  512         dropout_256[0][0]                \n","__________________________________________________________________________________________________\n","activation_257 (Activation)     (None, 28, 28, 128)  0           bn_layer_18[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_18 (Conv2D)          (None, 28, 28, 32)   36896       activation_257[0][0]             \n","__________________________________________________________________________________________________\n","dropout_257 (Dropout)           (None, 28, 28, 32)   0           conv_layer_18[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_104 (Concatenate)   (None, 28, 28, 64)   0           dropout_255[0][0]                \n","                                                                 dropout_257[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_19 (BatchNormalization (None, 28, 28, 64)   256         concatenate_104[0][0]            \n","__________________________________________________________________________________________________\n","activation_258 (Activation)     (None, 28, 28, 64)   0           bn_layer_19[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_19 (Conv2D)          (None, 28, 28, 128)  8320        activation_258[0][0]             \n","__________________________________________________________________________________________________\n","dropout_258 (Dropout)           (None, 28, 28, 128)  0           conv_layer_19[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_20 (BatchNormalization (None, 28, 28, 128)  512         dropout_258[0][0]                \n","__________________________________________________________________________________________________\n","activation_259 (Activation)     (None, 28, 28, 128)  0           bn_layer_20[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_20 (Conv2D)          (None, 28, 28, 32)   36896       activation_259[0][0]             \n","__________________________________________________________________________________________________\n","dropout_259 (Dropout)           (None, 28, 28, 32)   0           conv_layer_20[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_105 (Concatenate)   (None, 28, 28, 96)   0           dropout_255[0][0]                \n","                                                                 dropout_257[0][0]                \n","                                                                 dropout_259[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_21 (BatchNormalization (None, 28, 28, 96)   384         concatenate_105[0][0]            \n","__________________________________________________________________________________________________\n","activation_260 (Activation)     (None, 28, 28, 96)   0           bn_layer_21[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_21 (Conv2D)          (None, 28, 28, 128)  12416       activation_260[0][0]             \n","__________________________________________________________________________________________________\n","dropout_260 (Dropout)           (None, 28, 28, 128)  0           conv_layer_21[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_22 (BatchNormalization (None, 28, 28, 128)  512         dropout_260[0][0]                \n","__________________________________________________________________________________________________\n","activation_261 (Activation)     (None, 28, 28, 128)  0           bn_layer_22[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_22 (Conv2D)          (None, 28, 28, 32)   36896       activation_261[0][0]             \n","__________________________________________________________________________________________________\n","dropout_261 (Dropout)           (None, 28, 28, 32)   0           conv_layer_22[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_106 (Concatenate)   (None, 28, 28, 128)  0           dropout_255[0][0]                \n","                                                                 dropout_257[0][0]                \n","                                                                 dropout_259[0][0]                \n","                                                                 dropout_261[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_23 (BatchNormalization (None, 28, 28, 128)  512         concatenate_106[0][0]            \n","__________________________________________________________________________________________________\n","activation_262 (Activation)     (None, 28, 28, 128)  0           bn_layer_23[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_23 (Conv2D)          (None, 28, 28, 128)  16512       activation_262[0][0]             \n","__________________________________________________________________________________________________\n","dropout_262 (Dropout)           (None, 28, 28, 128)  0           conv_layer_23[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_24 (BatchNormalization (None, 28, 28, 128)  512         dropout_262[0][0]                \n","__________________________________________________________________________________________________\n","activation_263 (Activation)     (None, 28, 28, 128)  0           bn_layer_24[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_24 (Conv2D)          (None, 28, 28, 32)   36896       activation_263[0][0]             \n","__________________________________________________________________________________________________\n","dropout_263 (Dropout)           (None, 28, 28, 32)   0           conv_layer_24[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_107 (Concatenate)   (None, 28, 28, 160)  0           dropout_255[0][0]                \n","                                                                 dropout_257[0][0]                \n","                                                                 dropout_259[0][0]                \n","                                                                 dropout_261[0][0]                \n","                                                                 dropout_263[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_25 (BatchNormalization (None, 28, 28, 160)  640         concatenate_107[0][0]            \n","__________________________________________________________________________________________________\n","activation_264 (Activation)     (None, 28, 28, 160)  0           bn_layer_25[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_25 (Conv2D)          (None, 28, 28, 128)  20608       activation_264[0][0]             \n","__________________________________________________________________________________________________\n","dropout_264 (Dropout)           (None, 28, 28, 128)  0           conv_layer_25[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_26 (BatchNormalization (None, 28, 28, 128)  512         dropout_264[0][0]                \n","__________________________________________________________________________________________________\n","activation_265 (Activation)     (None, 28, 28, 128)  0           bn_layer_26[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_26 (Conv2D)          (None, 28, 28, 32)   36896       activation_265[0][0]             \n","__________________________________________________________________________________________________\n","dropout_265 (Dropout)           (None, 28, 28, 32)   0           conv_layer_26[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_108 (Concatenate)   (None, 28, 28, 192)  0           dropout_255[0][0]                \n","                                                                 dropout_257[0][0]                \n","                                                                 dropout_259[0][0]                \n","                                                                 dropout_261[0][0]                \n","                                                                 dropout_263[0][0]                \n","                                                                 dropout_265[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_27 (BatchNormalization (None, 28, 28, 192)  768         concatenate_108[0][0]            \n","__________________________________________________________________________________________________\n","activation_266 (Activation)     (None, 28, 28, 192)  0           bn_layer_27[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_27 (Conv2D)          (None, 28, 28, 128)  24704       activation_266[0][0]             \n","__________________________________________________________________________________________________\n","dropout_266 (Dropout)           (None, 28, 28, 128)  0           conv_layer_27[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_28 (BatchNormalization (None, 28, 28, 128)  512         dropout_266[0][0]                \n","__________________________________________________________________________________________________\n","activation_267 (Activation)     (None, 28, 28, 128)  0           bn_layer_28[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_28 (Conv2D)          (None, 28, 28, 32)   36896       activation_267[0][0]             \n","__________________________________________________________________________________________________\n","dropout_267 (Dropout)           (None, 28, 28, 32)   0           conv_layer_28[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_109 (Concatenate)   (None, 28, 28, 224)  0           dropout_255[0][0]                \n","                                                                 dropout_257[0][0]                \n","                                                                 dropout_259[0][0]                \n","                                                                 dropout_261[0][0]                \n","                                                                 dropout_263[0][0]                \n","                                                                 dropout_265[0][0]                \n","                                                                 dropout_267[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_29 (BatchNormalization (None, 28, 28, 224)  896         concatenate_109[0][0]            \n","__________________________________________________________________________________________________\n","activation_268 (Activation)     (None, 28, 28, 224)  0           bn_layer_29[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_29 (Conv2D)          (None, 28, 28, 128)  28800       activation_268[0][0]             \n","__________________________________________________________________________________________________\n","dropout_268 (Dropout)           (None, 28, 28, 128)  0           conv_layer_29[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_30 (BatchNormalization (None, 28, 28, 128)  512         dropout_268[0][0]                \n","__________________________________________________________________________________________________\n","activation_269 (Activation)     (None, 28, 28, 128)  0           bn_layer_30[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_30 (Conv2D)          (None, 28, 28, 32)   36896       activation_269[0][0]             \n","__________________________________________________________________________________________________\n","dropout_269 (Dropout)           (None, 28, 28, 32)   0           conv_layer_30[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_110 (Concatenate)   (None, 28, 28, 256)  0           dropout_255[0][0]                \n","                                                                 dropout_257[0][0]                \n","                                                                 dropout_259[0][0]                \n","                                                                 dropout_261[0][0]                \n","                                                                 dropout_263[0][0]                \n","                                                                 dropout_265[0][0]                \n","                                                                 dropout_267[0][0]                \n","                                                                 dropout_269[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_31 (BatchNormalization (None, 28, 28, 256)  1024        concatenate_110[0][0]            \n","__________________________________________________________________________________________________\n","activation_270 (Activation)     (None, 28, 28, 256)  0           bn_layer_31[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_31 (Conv2D)          (None, 28, 28, 128)  32896       activation_270[0][0]             \n","__________________________________________________________________________________________________\n","dropout_270 (Dropout)           (None, 28, 28, 128)  0           conv_layer_31[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_32 (BatchNormalization (None, 28, 28, 128)  512         dropout_270[0][0]                \n","__________________________________________________________________________________________________\n","activation_271 (Activation)     (None, 28, 28, 128)  0           bn_layer_32[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_32 (Conv2D)          (None, 28, 28, 32)   36896       activation_271[0][0]             \n","__________________________________________________________________________________________________\n","dropout_271 (Dropout)           (None, 28, 28, 32)   0           conv_layer_32[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_111 (Concatenate)   (None, 28, 28, 288)  0           dropout_255[0][0]                \n","                                                                 dropout_257[0][0]                \n","                                                                 dropout_259[0][0]                \n","                                                                 dropout_261[0][0]                \n","                                                                 dropout_263[0][0]                \n","                                                                 dropout_265[0][0]                \n","                                                                 dropout_267[0][0]                \n","                                                                 dropout_269[0][0]                \n","                                                                 dropout_271[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_33 (BatchNormalization (None, 28, 28, 288)  1152        concatenate_111[0][0]            \n","__________________________________________________________________________________________________\n","activation_272 (Activation)     (None, 28, 28, 288)  0           bn_layer_33[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_33 (Conv2D)          (None, 28, 28, 128)  36992       activation_272[0][0]             \n","__________________________________________________________________________________________________\n","dropout_272 (Dropout)           (None, 28, 28, 128)  0           conv_layer_33[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_34 (BatchNormalization (None, 28, 28, 128)  512         dropout_272[0][0]                \n","__________________________________________________________________________________________________\n","activation_273 (Activation)     (None, 28, 28, 128)  0           bn_layer_34[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_34 (Conv2D)          (None, 28, 28, 32)   36896       activation_273[0][0]             \n","__________________________________________________________________________________________________\n","dropout_273 (Dropout)           (None, 28, 28, 32)   0           conv_layer_34[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_112 (Concatenate)   (None, 28, 28, 320)  0           dropout_255[0][0]                \n","                                                                 dropout_257[0][0]                \n","                                                                 dropout_259[0][0]                \n","                                                                 dropout_261[0][0]                \n","                                                                 dropout_263[0][0]                \n","                                                                 dropout_265[0][0]                \n","                                                                 dropout_267[0][0]                \n","                                                                 dropout_269[0][0]                \n","                                                                 dropout_271[0][0]                \n","                                                                 dropout_273[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_35 (BatchNormalization (None, 28, 28, 320)  1280        concatenate_112[0][0]            \n","__________________________________________________________________________________________________\n","activation_274 (Activation)     (None, 28, 28, 320)  0           bn_layer_35[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_35 (Conv2D)          (None, 28, 28, 128)  41088       activation_274[0][0]             \n","__________________________________________________________________________________________________\n","dropout_274 (Dropout)           (None, 28, 28, 128)  0           conv_layer_35[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_36 (BatchNormalization (None, 28, 28, 128)  512         dropout_274[0][0]                \n","__________________________________________________________________________________________________\n","activation_275 (Activation)     (None, 28, 28, 128)  0           bn_layer_36[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_36 (Conv2D)          (None, 28, 28, 32)   36896       activation_275[0][0]             \n","__________________________________________________________________________________________________\n","dropout_275 (Dropout)           (None, 28, 28, 32)   0           conv_layer_36[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_113 (Concatenate)   (None, 28, 28, 352)  0           dropout_255[0][0]                \n","                                                                 dropout_257[0][0]                \n","                                                                 dropout_259[0][0]                \n","                                                                 dropout_261[0][0]                \n","                                                                 dropout_263[0][0]                \n","                                                                 dropout_265[0][0]                \n","                                                                 dropout_267[0][0]                \n","                                                                 dropout_269[0][0]                \n","                                                                 dropout_271[0][0]                \n","                                                                 dropout_273[0][0]                \n","                                                                 dropout_275[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_37 (BatchNormalization (None, 28, 28, 352)  1408        concatenate_113[0][0]            \n","__________________________________________________________________________________________________\n","activation_276 (Activation)     (None, 28, 28, 352)  0           bn_layer_37[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_37 (Conv2D)          (None, 28, 28, 128)  45184       activation_276[0][0]             \n","__________________________________________________________________________________________________\n","dropout_276 (Dropout)           (None, 28, 28, 128)  0           conv_layer_37[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_38 (BatchNormalization (None, 28, 28, 128)  512         dropout_276[0][0]                \n","__________________________________________________________________________________________________\n","activation_277 (Activation)     (None, 28, 28, 128)  0           bn_layer_38[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_38 (Conv2D)          (None, 28, 28, 32)   36896       activation_277[0][0]             \n","__________________________________________________________________________________________________\n","dropout_277 (Dropout)           (None, 28, 28, 32)   0           conv_layer_38[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_39 (BatchNormalization (None, 28, 28, 32)   128         dropout_277[0][0]                \n","__________________________________________________________________________________________________\n","activation_278 (Activation)     (None, 28, 28, 32)   0           bn_layer_39[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_39 (Conv2D)          (None, 28, 28, 32)   1056        activation_278[0][0]             \n","__________________________________________________________________________________________________\n","dropout_278 (Dropout)           (None, 28, 28, 32)   0           conv_layer_39[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_7 (AveragePoo (None, 14, 14, 32)   0           dropout_278[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_40 (BatchNormalization (None, 14, 14, 32)   128         average_pooling2d_7[0][0]        \n","__________________________________________________________________________________________________\n","activation_279 (Activation)     (None, 14, 14, 32)   0           bn_layer_40[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_40 (Conv2D)          (None, 14, 14, 128)  4224        activation_279[0][0]             \n","__________________________________________________________________________________________________\n","dropout_279 (Dropout)           (None, 14, 14, 128)  0           conv_layer_40[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_41 (BatchNormalization (None, 14, 14, 128)  512         dropout_279[0][0]                \n","__________________________________________________________________________________________________\n","activation_280 (Activation)     (None, 14, 14, 128)  0           bn_layer_41[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_41 (Conv2D)          (None, 14, 14, 32)   36896       activation_280[0][0]             \n","__________________________________________________________________________________________________\n","dropout_280 (Dropout)           (None, 14, 14, 32)   0           conv_layer_41[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_42 (BatchNormalization (None, 14, 14, 32)   128         dropout_280[0][0]                \n","__________________________________________________________________________________________________\n","activation_281 (Activation)     (None, 14, 14, 32)   0           bn_layer_42[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_42 (Conv2D)          (None, 14, 14, 128)  4224        activation_281[0][0]             \n","__________________________________________________________________________________________________\n","dropout_281 (Dropout)           (None, 14, 14, 128)  0           conv_layer_42[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_43 (BatchNormalization (None, 14, 14, 128)  512         dropout_281[0][0]                \n","__________________________________________________________________________________________________\n","activation_282 (Activation)     (None, 14, 14, 128)  0           bn_layer_43[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_43 (Conv2D)          (None, 14, 14, 32)   36896       activation_282[0][0]             \n","__________________________________________________________________________________________________\n","dropout_282 (Dropout)           (None, 14, 14, 32)   0           conv_layer_43[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_114 (Concatenate)   (None, 14, 14, 64)   0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_44 (BatchNormalization (None, 14, 14, 64)   256         concatenate_114[0][0]            \n","__________________________________________________________________________________________________\n","activation_283 (Activation)     (None, 14, 14, 64)   0           bn_layer_44[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_44 (Conv2D)          (None, 14, 14, 128)  8320        activation_283[0][0]             \n","__________________________________________________________________________________________________\n","dropout_283 (Dropout)           (None, 14, 14, 128)  0           conv_layer_44[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_45 (BatchNormalization (None, 14, 14, 128)  512         dropout_283[0][0]                \n","__________________________________________________________________________________________________\n","activation_284 (Activation)     (None, 14, 14, 128)  0           bn_layer_45[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_45 (Conv2D)          (None, 14, 14, 32)   36896       activation_284[0][0]             \n","__________________________________________________________________________________________________\n","dropout_284 (Dropout)           (None, 14, 14, 32)   0           conv_layer_45[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_115 (Concatenate)   (None, 14, 14, 96)   0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_46 (BatchNormalization (None, 14, 14, 96)   384         concatenate_115[0][0]            \n","__________________________________________________________________________________________________\n","activation_285 (Activation)     (None, 14, 14, 96)   0           bn_layer_46[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_46 (Conv2D)          (None, 14, 14, 128)  12416       activation_285[0][0]             \n","__________________________________________________________________________________________________\n","dropout_285 (Dropout)           (None, 14, 14, 128)  0           conv_layer_46[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_47 (BatchNormalization (None, 14, 14, 128)  512         dropout_285[0][0]                \n","__________________________________________________________________________________________________\n","activation_286 (Activation)     (None, 14, 14, 128)  0           bn_layer_47[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_47 (Conv2D)          (None, 14, 14, 32)   36896       activation_286[0][0]             \n","__________________________________________________________________________________________________\n","dropout_286 (Dropout)           (None, 14, 14, 32)   0           conv_layer_47[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_116 (Concatenate)   (None, 14, 14, 128)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_48 (BatchNormalization (None, 14, 14, 128)  512         concatenate_116[0][0]            \n","__________________________________________________________________________________________________\n","activation_287 (Activation)     (None, 14, 14, 128)  0           bn_layer_48[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_48 (Conv2D)          (None, 14, 14, 128)  16512       activation_287[0][0]             \n","__________________________________________________________________________________________________\n","dropout_287 (Dropout)           (None, 14, 14, 128)  0           conv_layer_48[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_49 (BatchNormalization (None, 14, 14, 128)  512         dropout_287[0][0]                \n","__________________________________________________________________________________________________\n","activation_288 (Activation)     (None, 14, 14, 128)  0           bn_layer_49[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_49 (Conv2D)          (None, 14, 14, 32)   36896       activation_288[0][0]             \n","__________________________________________________________________________________________________\n","dropout_288 (Dropout)           (None, 14, 14, 32)   0           conv_layer_49[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_117 (Concatenate)   (None, 14, 14, 160)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_50 (BatchNormalization (None, 14, 14, 160)  640         concatenate_117[0][0]            \n","__________________________________________________________________________________________________\n","activation_289 (Activation)     (None, 14, 14, 160)  0           bn_layer_50[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_50 (Conv2D)          (None, 14, 14, 128)  20608       activation_289[0][0]             \n","__________________________________________________________________________________________________\n","dropout_289 (Dropout)           (None, 14, 14, 128)  0           conv_layer_50[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_51 (BatchNormalization (None, 14, 14, 128)  512         dropout_289[0][0]                \n","__________________________________________________________________________________________________\n","activation_290 (Activation)     (None, 14, 14, 128)  0           bn_layer_51[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_51 (Conv2D)          (None, 14, 14, 32)   36896       activation_290[0][0]             \n","__________________________________________________________________________________________________\n","dropout_290 (Dropout)           (None, 14, 14, 32)   0           conv_layer_51[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_118 (Concatenate)   (None, 14, 14, 192)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_52 (BatchNormalization (None, 14, 14, 192)  768         concatenate_118[0][0]            \n","__________________________________________________________________________________________________\n","activation_291 (Activation)     (None, 14, 14, 192)  0           bn_layer_52[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_52 (Conv2D)          (None, 14, 14, 128)  24704       activation_291[0][0]             \n","__________________________________________________________________________________________________\n","dropout_291 (Dropout)           (None, 14, 14, 128)  0           conv_layer_52[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_53 (BatchNormalization (None, 14, 14, 128)  512         dropout_291[0][0]                \n","__________________________________________________________________________________________________\n","activation_292 (Activation)     (None, 14, 14, 128)  0           bn_layer_53[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_53 (Conv2D)          (None, 14, 14, 32)   36896       activation_292[0][0]             \n","__________________________________________________________________________________________________\n","dropout_292 (Dropout)           (None, 14, 14, 32)   0           conv_layer_53[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_119 (Concatenate)   (None, 14, 14, 224)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_54 (BatchNormalization (None, 14, 14, 224)  896         concatenate_119[0][0]            \n","__________________________________________________________________________________________________\n","activation_293 (Activation)     (None, 14, 14, 224)  0           bn_layer_54[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_54 (Conv2D)          (None, 14, 14, 128)  28800       activation_293[0][0]             \n","__________________________________________________________________________________________________\n","dropout_293 (Dropout)           (None, 14, 14, 128)  0           conv_layer_54[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_55 (BatchNormalization (None, 14, 14, 128)  512         dropout_293[0][0]                \n","__________________________________________________________________________________________________\n","activation_294 (Activation)     (None, 14, 14, 128)  0           bn_layer_55[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_55 (Conv2D)          (None, 14, 14, 32)   36896       activation_294[0][0]             \n","__________________________________________________________________________________________________\n","dropout_294 (Dropout)           (None, 14, 14, 32)   0           conv_layer_55[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_120 (Concatenate)   (None, 14, 14, 256)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_56 (BatchNormalization (None, 14, 14, 256)  1024        concatenate_120[0][0]            \n","__________________________________________________________________________________________________\n","activation_295 (Activation)     (None, 14, 14, 256)  0           bn_layer_56[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_56 (Conv2D)          (None, 14, 14, 128)  32896       activation_295[0][0]             \n","__________________________________________________________________________________________________\n","dropout_295 (Dropout)           (None, 14, 14, 128)  0           conv_layer_56[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_57 (BatchNormalization (None, 14, 14, 128)  512         dropout_295[0][0]                \n","__________________________________________________________________________________________________\n","activation_296 (Activation)     (None, 14, 14, 128)  0           bn_layer_57[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_57 (Conv2D)          (None, 14, 14, 32)   36896       activation_296[0][0]             \n","__________________________________________________________________________________________________\n","dropout_296 (Dropout)           (None, 14, 14, 32)   0           conv_layer_57[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_121 (Concatenate)   (None, 14, 14, 288)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_58 (BatchNormalization (None, 14, 14, 288)  1152        concatenate_121[0][0]            \n","__________________________________________________________________________________________________\n","activation_297 (Activation)     (None, 14, 14, 288)  0           bn_layer_58[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_58 (Conv2D)          (None, 14, 14, 128)  36992       activation_297[0][0]             \n","__________________________________________________________________________________________________\n","dropout_297 (Dropout)           (None, 14, 14, 128)  0           conv_layer_58[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_59 (BatchNormalization (None, 14, 14, 128)  512         dropout_297[0][0]                \n","__________________________________________________________________________________________________\n","activation_298 (Activation)     (None, 14, 14, 128)  0           bn_layer_59[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_59 (Conv2D)          (None, 14, 14, 32)   36896       activation_298[0][0]             \n","__________________________________________________________________________________________________\n","dropout_298 (Dropout)           (None, 14, 14, 32)   0           conv_layer_59[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_122 (Concatenate)   (None, 14, 14, 320)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_60 (BatchNormalization (None, 14, 14, 320)  1280        concatenate_122[0][0]            \n","__________________________________________________________________________________________________\n","activation_299 (Activation)     (None, 14, 14, 320)  0           bn_layer_60[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_60 (Conv2D)          (None, 14, 14, 128)  41088       activation_299[0][0]             \n","__________________________________________________________________________________________________\n","dropout_299 (Dropout)           (None, 14, 14, 128)  0           conv_layer_60[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_61 (BatchNormalization (None, 14, 14, 128)  512         dropout_299[0][0]                \n","__________________________________________________________________________________________________\n","activation_300 (Activation)     (None, 14, 14, 128)  0           bn_layer_61[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_61 (Conv2D)          (None, 14, 14, 32)   36896       activation_300[0][0]             \n","__________________________________________________________________________________________________\n","dropout_300 (Dropout)           (None, 14, 14, 32)   0           conv_layer_61[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_123 (Concatenate)   (None, 14, 14, 352)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_62 (BatchNormalization (None, 14, 14, 352)  1408        concatenate_123[0][0]            \n","__________________________________________________________________________________________________\n","activation_301 (Activation)     (None, 14, 14, 352)  0           bn_layer_62[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_62 (Conv2D)          (None, 14, 14, 128)  45184       activation_301[0][0]             \n","__________________________________________________________________________________________________\n","dropout_301 (Dropout)           (None, 14, 14, 128)  0           conv_layer_62[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_63 (BatchNormalization (None, 14, 14, 128)  512         dropout_301[0][0]                \n","__________________________________________________________________________________________________\n","activation_302 (Activation)     (None, 14, 14, 128)  0           bn_layer_63[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_63 (Conv2D)          (None, 14, 14, 32)   36896       activation_302[0][0]             \n","__________________________________________________________________________________________________\n","dropout_302 (Dropout)           (None, 14, 14, 32)   0           conv_layer_63[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_124 (Concatenate)   (None, 14, 14, 384)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","                                                                 dropout_302[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_64 (BatchNormalization (None, 14, 14, 384)  1536        concatenate_124[0][0]            \n","__________________________________________________________________________________________________\n","activation_303 (Activation)     (None, 14, 14, 384)  0           bn_layer_64[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_64 (Conv2D)          (None, 14, 14, 128)  49280       activation_303[0][0]             \n","__________________________________________________________________________________________________\n","dropout_303 (Dropout)           (None, 14, 14, 128)  0           conv_layer_64[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_65 (BatchNormalization (None, 14, 14, 128)  512         dropout_303[0][0]                \n","__________________________________________________________________________________________________\n","activation_304 (Activation)     (None, 14, 14, 128)  0           bn_layer_65[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_65 (Conv2D)          (None, 14, 14, 32)   36896       activation_304[0][0]             \n","__________________________________________________________________________________________________\n","dropout_304 (Dropout)           (None, 14, 14, 32)   0           conv_layer_65[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_125 (Concatenate)   (None, 14, 14, 416)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","                                                                 dropout_302[0][0]                \n","                                                                 dropout_304[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_66 (BatchNormalization (None, 14, 14, 416)  1664        concatenate_125[0][0]            \n","__________________________________________________________________________________________________\n","activation_305 (Activation)     (None, 14, 14, 416)  0           bn_layer_66[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_66 (Conv2D)          (None, 14, 14, 128)  53376       activation_305[0][0]             \n","__________________________________________________________________________________________________\n","dropout_305 (Dropout)           (None, 14, 14, 128)  0           conv_layer_66[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_67 (BatchNormalization (None, 14, 14, 128)  512         dropout_305[0][0]                \n","__________________________________________________________________________________________________\n","activation_306 (Activation)     (None, 14, 14, 128)  0           bn_layer_67[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_67 (Conv2D)          (None, 14, 14, 32)   36896       activation_306[0][0]             \n","__________________________________________________________________________________________________\n","dropout_306 (Dropout)           (None, 14, 14, 32)   0           conv_layer_67[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_126 (Concatenate)   (None, 14, 14, 448)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","                                                                 dropout_302[0][0]                \n","                                                                 dropout_304[0][0]                \n","                                                                 dropout_306[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_68 (BatchNormalization (None, 14, 14, 448)  1792        concatenate_126[0][0]            \n","__________________________________________________________________________________________________\n","activation_307 (Activation)     (None, 14, 14, 448)  0           bn_layer_68[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_68 (Conv2D)          (None, 14, 14, 128)  57472       activation_307[0][0]             \n","__________________________________________________________________________________________________\n","dropout_307 (Dropout)           (None, 14, 14, 128)  0           conv_layer_68[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_69 (BatchNormalization (None, 14, 14, 128)  512         dropout_307[0][0]                \n","__________________________________________________________________________________________________\n","activation_308 (Activation)     (None, 14, 14, 128)  0           bn_layer_69[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_69 (Conv2D)          (None, 14, 14, 32)   36896       activation_308[0][0]             \n","__________________________________________________________________________________________________\n","dropout_308 (Dropout)           (None, 14, 14, 32)   0           conv_layer_69[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_127 (Concatenate)   (None, 14, 14, 480)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","                                                                 dropout_302[0][0]                \n","                                                                 dropout_304[0][0]                \n","                                                                 dropout_306[0][0]                \n","                                                                 dropout_308[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_70 (BatchNormalization (None, 14, 14, 480)  1920        concatenate_127[0][0]            \n","__________________________________________________________________________________________________\n","activation_309 (Activation)     (None, 14, 14, 480)  0           bn_layer_70[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_70 (Conv2D)          (None, 14, 14, 128)  61568       activation_309[0][0]             \n","__________________________________________________________________________________________________\n","dropout_309 (Dropout)           (None, 14, 14, 128)  0           conv_layer_70[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_71 (BatchNormalization (None, 14, 14, 128)  512         dropout_309[0][0]                \n","__________________________________________________________________________________________________\n","activation_310 (Activation)     (None, 14, 14, 128)  0           bn_layer_71[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_71 (Conv2D)          (None, 14, 14, 32)   36896       activation_310[0][0]             \n","__________________________________________________________________________________________________\n","dropout_310 (Dropout)           (None, 14, 14, 32)   0           conv_layer_71[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_128 (Concatenate)   (None, 14, 14, 512)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","                                                                 dropout_302[0][0]                \n","                                                                 dropout_304[0][0]                \n","                                                                 dropout_306[0][0]                \n","                                                                 dropout_308[0][0]                \n","                                                                 dropout_310[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_72 (BatchNormalization (None, 14, 14, 512)  2048        concatenate_128[0][0]            \n","__________________________________________________________________________________________________\n","activation_311 (Activation)     (None, 14, 14, 512)  0           bn_layer_72[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_72 (Conv2D)          (None, 14, 14, 128)  65664       activation_311[0][0]             \n","__________________________________________________________________________________________________\n","dropout_311 (Dropout)           (None, 14, 14, 128)  0           conv_layer_72[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_73 (BatchNormalization (None, 14, 14, 128)  512         dropout_311[0][0]                \n","__________________________________________________________________________________________________\n","activation_312 (Activation)     (None, 14, 14, 128)  0           bn_layer_73[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_73 (Conv2D)          (None, 14, 14, 32)   36896       activation_312[0][0]             \n","__________________________________________________________________________________________________\n","dropout_312 (Dropout)           (None, 14, 14, 32)   0           conv_layer_73[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_129 (Concatenate)   (None, 14, 14, 544)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","                                                                 dropout_302[0][0]                \n","                                                                 dropout_304[0][0]                \n","                                                                 dropout_306[0][0]                \n","                                                                 dropout_308[0][0]                \n","                                                                 dropout_310[0][0]                \n","                                                                 dropout_312[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_74 (BatchNormalization (None, 14, 14, 544)  2176        concatenate_129[0][0]            \n","__________________________________________________________________________________________________\n","activation_313 (Activation)     (None, 14, 14, 544)  0           bn_layer_74[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_74 (Conv2D)          (None, 14, 14, 128)  69760       activation_313[0][0]             \n","__________________________________________________________________________________________________\n","dropout_313 (Dropout)           (None, 14, 14, 128)  0           conv_layer_74[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_75 (BatchNormalization (None, 14, 14, 128)  512         dropout_313[0][0]                \n","__________________________________________________________________________________________________\n","activation_314 (Activation)     (None, 14, 14, 128)  0           bn_layer_75[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_75 (Conv2D)          (None, 14, 14, 32)   36896       activation_314[0][0]             \n","__________________________________________________________________________________________________\n","dropout_314 (Dropout)           (None, 14, 14, 32)   0           conv_layer_75[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_130 (Concatenate)   (None, 14, 14, 576)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","                                                                 dropout_302[0][0]                \n","                                                                 dropout_304[0][0]                \n","                                                                 dropout_306[0][0]                \n","                                                                 dropout_308[0][0]                \n","                                                                 dropout_310[0][0]                \n","                                                                 dropout_312[0][0]                \n","                                                                 dropout_314[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_76 (BatchNormalization (None, 14, 14, 576)  2304        concatenate_130[0][0]            \n","__________________________________________________________________________________________________\n","activation_315 (Activation)     (None, 14, 14, 576)  0           bn_layer_76[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_76 (Conv2D)          (None, 14, 14, 128)  73856       activation_315[0][0]             \n","__________________________________________________________________________________________________\n","dropout_315 (Dropout)           (None, 14, 14, 128)  0           conv_layer_76[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_77 (BatchNormalization (None, 14, 14, 128)  512         dropout_315[0][0]                \n","__________________________________________________________________________________________________\n","activation_316 (Activation)     (None, 14, 14, 128)  0           bn_layer_77[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_77 (Conv2D)          (None, 14, 14, 32)   36896       activation_316[0][0]             \n","__________________________________________________________________________________________________\n","dropout_316 (Dropout)           (None, 14, 14, 32)   0           conv_layer_77[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_131 (Concatenate)   (None, 14, 14, 608)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","                                                                 dropout_302[0][0]                \n","                                                                 dropout_304[0][0]                \n","                                                                 dropout_306[0][0]                \n","                                                                 dropout_308[0][0]                \n","                                                                 dropout_310[0][0]                \n","                                                                 dropout_312[0][0]                \n","                                                                 dropout_314[0][0]                \n","                                                                 dropout_316[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_78 (BatchNormalization (None, 14, 14, 608)  2432        concatenate_131[0][0]            \n","__________________________________________________________________________________________________\n","activation_317 (Activation)     (None, 14, 14, 608)  0           bn_layer_78[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_78 (Conv2D)          (None, 14, 14, 128)  77952       activation_317[0][0]             \n","__________________________________________________________________________________________________\n","dropout_317 (Dropout)           (None, 14, 14, 128)  0           conv_layer_78[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_79 (BatchNormalization (None, 14, 14, 128)  512         dropout_317[0][0]                \n","__________________________________________________________________________________________________\n","activation_318 (Activation)     (None, 14, 14, 128)  0           bn_layer_79[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_79 (Conv2D)          (None, 14, 14, 32)   36896       activation_318[0][0]             \n","__________________________________________________________________________________________________\n","dropout_318 (Dropout)           (None, 14, 14, 32)   0           conv_layer_79[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_132 (Concatenate)   (None, 14, 14, 640)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","                                                                 dropout_302[0][0]                \n","                                                                 dropout_304[0][0]                \n","                                                                 dropout_306[0][0]                \n","                                                                 dropout_308[0][0]                \n","                                                                 dropout_310[0][0]                \n","                                                                 dropout_312[0][0]                \n","                                                                 dropout_314[0][0]                \n","                                                                 dropout_316[0][0]                \n","                                                                 dropout_318[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_80 (BatchNormalization (None, 14, 14, 640)  2560        concatenate_132[0][0]            \n","__________________________________________________________________________________________________\n","activation_319 (Activation)     (None, 14, 14, 640)  0           bn_layer_80[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_80 (Conv2D)          (None, 14, 14, 128)  82048       activation_319[0][0]             \n","__________________________________________________________________________________________________\n","dropout_319 (Dropout)           (None, 14, 14, 128)  0           conv_layer_80[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_81 (BatchNormalization (None, 14, 14, 128)  512         dropout_319[0][0]                \n","__________________________________________________________________________________________________\n","activation_320 (Activation)     (None, 14, 14, 128)  0           bn_layer_81[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_81 (Conv2D)          (None, 14, 14, 32)   36896       activation_320[0][0]             \n","__________________________________________________________________________________________________\n","dropout_320 (Dropout)           (None, 14, 14, 32)   0           conv_layer_81[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_133 (Concatenate)   (None, 14, 14, 672)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","                                                                 dropout_302[0][0]                \n","                                                                 dropout_304[0][0]                \n","                                                                 dropout_306[0][0]                \n","                                                                 dropout_308[0][0]                \n","                                                                 dropout_310[0][0]                \n","                                                                 dropout_312[0][0]                \n","                                                                 dropout_314[0][0]                \n","                                                                 dropout_316[0][0]                \n","                                                                 dropout_318[0][0]                \n","                                                                 dropout_320[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_82 (BatchNormalization (None, 14, 14, 672)  2688        concatenate_133[0][0]            \n","__________________________________________________________________________________________________\n","activation_321 (Activation)     (None, 14, 14, 672)  0           bn_layer_82[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_82 (Conv2D)          (None, 14, 14, 128)  86144       activation_321[0][0]             \n","__________________________________________________________________________________________________\n","dropout_321 (Dropout)           (None, 14, 14, 128)  0           conv_layer_82[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_83 (BatchNormalization (None, 14, 14, 128)  512         dropout_321[0][0]                \n","__________________________________________________________________________________________________\n","activation_322 (Activation)     (None, 14, 14, 128)  0           bn_layer_83[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_83 (Conv2D)          (None, 14, 14, 32)   36896       activation_322[0][0]             \n","__________________________________________________________________________________________________\n","dropout_322 (Dropout)           (None, 14, 14, 32)   0           conv_layer_83[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_134 (Concatenate)   (None, 14, 14, 704)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","                                                                 dropout_302[0][0]                \n","                                                                 dropout_304[0][0]                \n","                                                                 dropout_306[0][0]                \n","                                                                 dropout_308[0][0]                \n","                                                                 dropout_310[0][0]                \n","                                                                 dropout_312[0][0]                \n","                                                                 dropout_314[0][0]                \n","                                                                 dropout_316[0][0]                \n","                                                                 dropout_318[0][0]                \n","                                                                 dropout_320[0][0]                \n","                                                                 dropout_322[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_84 (BatchNormalization (None, 14, 14, 704)  2816        concatenate_134[0][0]            \n","__________________________________________________________________________________________________\n","activation_323 (Activation)     (None, 14, 14, 704)  0           bn_layer_84[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_84 (Conv2D)          (None, 14, 14, 128)  90240       activation_323[0][0]             \n","__________________________________________________________________________________________________\n","dropout_323 (Dropout)           (None, 14, 14, 128)  0           conv_layer_84[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_85 (BatchNormalization (None, 14, 14, 128)  512         dropout_323[0][0]                \n","__________________________________________________________________________________________________\n","activation_324 (Activation)     (None, 14, 14, 128)  0           bn_layer_85[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_85 (Conv2D)          (None, 14, 14, 32)   36896       activation_324[0][0]             \n","__________________________________________________________________________________________________\n","dropout_324 (Dropout)           (None, 14, 14, 32)   0           conv_layer_85[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_135 (Concatenate)   (None, 14, 14, 736)  0           dropout_280[0][0]                \n","                                                                 dropout_282[0][0]                \n","                                                                 dropout_284[0][0]                \n","                                                                 dropout_286[0][0]                \n","                                                                 dropout_288[0][0]                \n","                                                                 dropout_290[0][0]                \n","                                                                 dropout_292[0][0]                \n","                                                                 dropout_294[0][0]                \n","                                                                 dropout_296[0][0]                \n","                                                                 dropout_298[0][0]                \n","                                                                 dropout_300[0][0]                \n","                                                                 dropout_302[0][0]                \n","                                                                 dropout_304[0][0]                \n","                                                                 dropout_306[0][0]                \n","                                                                 dropout_308[0][0]                \n","                                                                 dropout_310[0][0]                \n","                                                                 dropout_312[0][0]                \n","                                                                 dropout_314[0][0]                \n","                                                                 dropout_316[0][0]                \n","                                                                 dropout_318[0][0]                \n","                                                                 dropout_320[0][0]                \n","                                                                 dropout_322[0][0]                \n","                                                                 dropout_324[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_86 (BatchNormalization (None, 14, 14, 736)  2944        concatenate_135[0][0]            \n","__________________________________________________________________________________________________\n","activation_325 (Activation)     (None, 14, 14, 736)  0           bn_layer_86[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_86 (Conv2D)          (None, 14, 14, 128)  94336       activation_325[0][0]             \n","__________________________________________________________________________________________________\n","dropout_325 (Dropout)           (None, 14, 14, 128)  0           conv_layer_86[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_87 (BatchNormalization (None, 14, 14, 128)  512         dropout_325[0][0]                \n","__________________________________________________________________________________________________\n","activation_326 (Activation)     (None, 14, 14, 128)  0           bn_layer_87[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_87 (Conv2D)          (None, 14, 14, 32)   36896       activation_326[0][0]             \n","__________________________________________________________________________________________________\n","dropout_326 (Dropout)           (None, 14, 14, 32)   0           conv_layer_87[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_88 (BatchNormalization (None, 14, 14, 32)   128         dropout_326[0][0]                \n","__________________________________________________________________________________________________\n","activation_327 (Activation)     (None, 14, 14, 32)   0           bn_layer_88[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_88 (Conv2D)          (None, 14, 14, 32)   1056        activation_327[0][0]             \n","__________________________________________________________________________________________________\n","dropout_327 (Dropout)           (None, 14, 14, 32)   0           conv_layer_88[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_8 (AveragePoo (None, 7, 7, 32)     0           dropout_327[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_89 (BatchNormalization (None, 7, 7, 32)     128         average_pooling2d_8[0][0]        \n","__________________________________________________________________________________________________\n","activation_328 (Activation)     (None, 7, 7, 32)     0           bn_layer_89[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_89 (Conv2D)          (None, 7, 7, 128)    4224        activation_328[0][0]             \n","__________________________________________________________________________________________________\n","dropout_328 (Dropout)           (None, 7, 7, 128)    0           conv_layer_89[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_90 (BatchNormalization (None, 7, 7, 128)    512         dropout_328[0][0]                \n","__________________________________________________________________________________________________\n","activation_329 (Activation)     (None, 7, 7, 128)    0           bn_layer_90[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_90 (Conv2D)          (None, 7, 7, 32)     36896       activation_329[0][0]             \n","__________________________________________________________________________________________________\n","dropout_329 (Dropout)           (None, 7, 7, 32)     0           conv_layer_90[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_91 (BatchNormalization (None, 7, 7, 32)     128         dropout_329[0][0]                \n","__________________________________________________________________________________________________\n","activation_330 (Activation)     (None, 7, 7, 32)     0           bn_layer_91[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_91 (Conv2D)          (None, 7, 7, 128)    4224        activation_330[0][0]             \n","__________________________________________________________________________________________________\n","dropout_330 (Dropout)           (None, 7, 7, 128)    0           conv_layer_91[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_92 (BatchNormalization (None, 7, 7, 128)    512         dropout_330[0][0]                \n","__________________________________________________________________________________________________\n","activation_331 (Activation)     (None, 7, 7, 128)    0           bn_layer_92[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_92 (Conv2D)          (None, 7, 7, 32)     36896       activation_331[0][0]             \n","__________________________________________________________________________________________________\n","dropout_331 (Dropout)           (None, 7, 7, 32)     0           conv_layer_92[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_136 (Concatenate)   (None, 7, 7, 64)     0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_93 (BatchNormalization (None, 7, 7, 64)     256         concatenate_136[0][0]            \n","__________________________________________________________________________________________________\n","activation_332 (Activation)     (None, 7, 7, 64)     0           bn_layer_93[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_93 (Conv2D)          (None, 7, 7, 128)    8320        activation_332[0][0]             \n","__________________________________________________________________________________________________\n","dropout_332 (Dropout)           (None, 7, 7, 128)    0           conv_layer_93[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_94 (BatchNormalization (None, 7, 7, 128)    512         dropout_332[0][0]                \n","__________________________________________________________________________________________________\n","activation_333 (Activation)     (None, 7, 7, 128)    0           bn_layer_94[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_94 (Conv2D)          (None, 7, 7, 32)     36896       activation_333[0][0]             \n","__________________________________________________________________________________________________\n","dropout_333 (Dropout)           (None, 7, 7, 32)     0           conv_layer_94[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_137 (Concatenate)   (None, 7, 7, 96)     0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_95 (BatchNormalization (None, 7, 7, 96)     384         concatenate_137[0][0]            \n","__________________________________________________________________________________________________\n","activation_334 (Activation)     (None, 7, 7, 96)     0           bn_layer_95[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_95 (Conv2D)          (None, 7, 7, 128)    12416       activation_334[0][0]             \n","__________________________________________________________________________________________________\n","dropout_334 (Dropout)           (None, 7, 7, 128)    0           conv_layer_95[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_96 (BatchNormalization (None, 7, 7, 128)    512         dropout_334[0][0]                \n","__________________________________________________________________________________________________\n","activation_335 (Activation)     (None, 7, 7, 128)    0           bn_layer_96[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_96 (Conv2D)          (None, 7, 7, 32)     36896       activation_335[0][0]             \n","__________________________________________________________________________________________________\n","dropout_335 (Dropout)           (None, 7, 7, 32)     0           conv_layer_96[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_138 (Concatenate)   (None, 7, 7, 128)    0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","                                                                 dropout_335[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_97 (BatchNormalization (None, 7, 7, 128)    512         concatenate_138[0][0]            \n","__________________________________________________________________________________________________\n","activation_336 (Activation)     (None, 7, 7, 128)    0           bn_layer_97[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_97 (Conv2D)          (None, 7, 7, 128)    16512       activation_336[0][0]             \n","__________________________________________________________________________________________________\n","dropout_336 (Dropout)           (None, 7, 7, 128)    0           conv_layer_97[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_98 (BatchNormalization (None, 7, 7, 128)    512         dropout_336[0][0]                \n","__________________________________________________________________________________________________\n","activation_337 (Activation)     (None, 7, 7, 128)    0           bn_layer_98[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_98 (Conv2D)          (None, 7, 7, 32)     36896       activation_337[0][0]             \n","__________________________________________________________________________________________________\n","dropout_337 (Dropout)           (None, 7, 7, 32)     0           conv_layer_98[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_139 (Concatenate)   (None, 7, 7, 160)    0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","                                                                 dropout_335[0][0]                \n","                                                                 dropout_337[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_99 (BatchNormalization (None, 7, 7, 160)    640         concatenate_139[0][0]            \n","__________________________________________________________________________________________________\n","activation_338 (Activation)     (None, 7, 7, 160)    0           bn_layer_99[0][0]                \n","__________________________________________________________________________________________________\n","conv_layer_99 (Conv2D)          (None, 7, 7, 128)    20608       activation_338[0][0]             \n","__________________________________________________________________________________________________\n","dropout_338 (Dropout)           (None, 7, 7, 128)    0           conv_layer_99[0][0]              \n","__________________________________________________________________________________________________\n","bn_layer_100 (BatchNormalizatio (None, 7, 7, 128)    512         dropout_338[0][0]                \n","__________________________________________________________________________________________________\n","activation_339 (Activation)     (None, 7, 7, 128)    0           bn_layer_100[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_100 (Conv2D)         (None, 7, 7, 32)     36896       activation_339[0][0]             \n","__________________________________________________________________________________________________\n","dropout_339 (Dropout)           (None, 7, 7, 32)     0           conv_layer_100[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_140 (Concatenate)   (None, 7, 7, 192)    0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","                                                                 dropout_335[0][0]                \n","                                                                 dropout_337[0][0]                \n","                                                                 dropout_339[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_101 (BatchNormalizatio (None, 7, 7, 192)    768         concatenate_140[0][0]            \n","__________________________________________________________________________________________________\n","activation_340 (Activation)     (None, 7, 7, 192)    0           bn_layer_101[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_101 (Conv2D)         (None, 7, 7, 128)    24704       activation_340[0][0]             \n","__________________________________________________________________________________________________\n","dropout_340 (Dropout)           (None, 7, 7, 128)    0           conv_layer_101[0][0]             \n","__________________________________________________________________________________________________\n","bn_layer_102 (BatchNormalizatio (None, 7, 7, 128)    512         dropout_340[0][0]                \n","__________________________________________________________________________________________________\n","activation_341 (Activation)     (None, 7, 7, 128)    0           bn_layer_102[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_102 (Conv2D)         (None, 7, 7, 32)     36896       activation_341[0][0]             \n","__________________________________________________________________________________________________\n","dropout_341 (Dropout)           (None, 7, 7, 32)     0           conv_layer_102[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_141 (Concatenate)   (None, 7, 7, 224)    0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","                                                                 dropout_335[0][0]                \n","                                                                 dropout_337[0][0]                \n","                                                                 dropout_339[0][0]                \n","                                                                 dropout_341[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_103 (BatchNormalizatio (None, 7, 7, 224)    896         concatenate_141[0][0]            \n","__________________________________________________________________________________________________\n","activation_342 (Activation)     (None, 7, 7, 224)    0           bn_layer_103[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_103 (Conv2D)         (None, 7, 7, 128)    28800       activation_342[0][0]             \n","__________________________________________________________________________________________________\n","dropout_342 (Dropout)           (None, 7, 7, 128)    0           conv_layer_103[0][0]             \n","__________________________________________________________________________________________________\n","bn_layer_104 (BatchNormalizatio (None, 7, 7, 128)    512         dropout_342[0][0]                \n","__________________________________________________________________________________________________\n","activation_343 (Activation)     (None, 7, 7, 128)    0           bn_layer_104[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_104 (Conv2D)         (None, 7, 7, 32)     36896       activation_343[0][0]             \n","__________________________________________________________________________________________________\n","dropout_343 (Dropout)           (None, 7, 7, 32)     0           conv_layer_104[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_142 (Concatenate)   (None, 7, 7, 256)    0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","                                                                 dropout_335[0][0]                \n","                                                                 dropout_337[0][0]                \n","                                                                 dropout_339[0][0]                \n","                                                                 dropout_341[0][0]                \n","                                                                 dropout_343[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_105 (BatchNormalizatio (None, 7, 7, 256)    1024        concatenate_142[0][0]            \n","__________________________________________________________________________________________________\n","activation_344 (Activation)     (None, 7, 7, 256)    0           bn_layer_105[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_105 (Conv2D)         (None, 7, 7, 128)    32896       activation_344[0][0]             \n","__________________________________________________________________________________________________\n","dropout_344 (Dropout)           (None, 7, 7, 128)    0           conv_layer_105[0][0]             \n","__________________________________________________________________________________________________\n","bn_layer_106 (BatchNormalizatio (None, 7, 7, 128)    512         dropout_344[0][0]                \n","__________________________________________________________________________________________________\n","activation_345 (Activation)     (None, 7, 7, 128)    0           bn_layer_106[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_106 (Conv2D)         (None, 7, 7, 32)     36896       activation_345[0][0]             \n","__________________________________________________________________________________________________\n","dropout_345 (Dropout)           (None, 7, 7, 32)     0           conv_layer_106[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_143 (Concatenate)   (None, 7, 7, 288)    0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","                                                                 dropout_335[0][0]                \n","                                                                 dropout_337[0][0]                \n","                                                                 dropout_339[0][0]                \n","                                                                 dropout_341[0][0]                \n","                                                                 dropout_343[0][0]                \n","                                                                 dropout_345[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_107 (BatchNormalizatio (None, 7, 7, 288)    1152        concatenate_143[0][0]            \n","__________________________________________________________________________________________________\n","activation_346 (Activation)     (None, 7, 7, 288)    0           bn_layer_107[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_107 (Conv2D)         (None, 7, 7, 128)    36992       activation_346[0][0]             \n","__________________________________________________________________________________________________\n","dropout_346 (Dropout)           (None, 7, 7, 128)    0           conv_layer_107[0][0]             \n","__________________________________________________________________________________________________\n","bn_layer_108 (BatchNormalizatio (None, 7, 7, 128)    512         dropout_346[0][0]                \n","__________________________________________________________________________________________________\n","activation_347 (Activation)     (None, 7, 7, 128)    0           bn_layer_108[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_108 (Conv2D)         (None, 7, 7, 32)     36896       activation_347[0][0]             \n","__________________________________________________________________________________________________\n","dropout_347 (Dropout)           (None, 7, 7, 32)     0           conv_layer_108[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_144 (Concatenate)   (None, 7, 7, 320)    0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","                                                                 dropout_335[0][0]                \n","                                                                 dropout_337[0][0]                \n","                                                                 dropout_339[0][0]                \n","                                                                 dropout_341[0][0]                \n","                                                                 dropout_343[0][0]                \n","                                                                 dropout_345[0][0]                \n","                                                                 dropout_347[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_109 (BatchNormalizatio (None, 7, 7, 320)    1280        concatenate_144[0][0]            \n","__________________________________________________________________________________________________\n","activation_348 (Activation)     (None, 7, 7, 320)    0           bn_layer_109[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_109 (Conv2D)         (None, 7, 7, 128)    41088       activation_348[0][0]             \n","__________________________________________________________________________________________________\n","dropout_348 (Dropout)           (None, 7, 7, 128)    0           conv_layer_109[0][0]             \n","__________________________________________________________________________________________________\n","bn_layer_110 (BatchNormalizatio (None, 7, 7, 128)    512         dropout_348[0][0]                \n","__________________________________________________________________________________________________\n","activation_349 (Activation)     (None, 7, 7, 128)    0           bn_layer_110[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_110 (Conv2D)         (None, 7, 7, 32)     36896       activation_349[0][0]             \n","__________________________________________________________________________________________________\n","dropout_349 (Dropout)           (None, 7, 7, 32)     0           conv_layer_110[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_145 (Concatenate)   (None, 7, 7, 352)    0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","                                                                 dropout_335[0][0]                \n","                                                                 dropout_337[0][0]                \n","                                                                 dropout_339[0][0]                \n","                                                                 dropout_341[0][0]                \n","                                                                 dropout_343[0][0]                \n","                                                                 dropout_345[0][0]                \n","                                                                 dropout_347[0][0]                \n","                                                                 dropout_349[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_111 (BatchNormalizatio (None, 7, 7, 352)    1408        concatenate_145[0][0]            \n","__________________________________________________________________________________________________\n","activation_350 (Activation)     (None, 7, 7, 352)    0           bn_layer_111[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_111 (Conv2D)         (None, 7, 7, 128)    45184       activation_350[0][0]             \n","__________________________________________________________________________________________________\n","dropout_350 (Dropout)           (None, 7, 7, 128)    0           conv_layer_111[0][0]             \n","__________________________________________________________________________________________________\n","bn_layer_112 (BatchNormalizatio (None, 7, 7, 128)    512         dropout_350[0][0]                \n","__________________________________________________________________________________________________\n","activation_351 (Activation)     (None, 7, 7, 128)    0           bn_layer_112[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_112 (Conv2D)         (None, 7, 7, 32)     36896       activation_351[0][0]             \n","__________________________________________________________________________________________________\n","dropout_351 (Dropout)           (None, 7, 7, 32)     0           conv_layer_112[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_146 (Concatenate)   (None, 7, 7, 384)    0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","                                                                 dropout_335[0][0]                \n","                                                                 dropout_337[0][0]                \n","                                                                 dropout_339[0][0]                \n","                                                                 dropout_341[0][0]                \n","                                                                 dropout_343[0][0]                \n","                                                                 dropout_345[0][0]                \n","                                                                 dropout_347[0][0]                \n","                                                                 dropout_349[0][0]                \n","                                                                 dropout_351[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_113 (BatchNormalizatio (None, 7, 7, 384)    1536        concatenate_146[0][0]            \n","__________________________________________________________________________________________________\n","activation_352 (Activation)     (None, 7, 7, 384)    0           bn_layer_113[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_113 (Conv2D)         (None, 7, 7, 128)    49280       activation_352[0][0]             \n","__________________________________________________________________________________________________\n","dropout_352 (Dropout)           (None, 7, 7, 128)    0           conv_layer_113[0][0]             \n","__________________________________________________________________________________________________\n","bn_layer_114 (BatchNormalizatio (None, 7, 7, 128)    512         dropout_352[0][0]                \n","__________________________________________________________________________________________________\n","activation_353 (Activation)     (None, 7, 7, 128)    0           bn_layer_114[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_114 (Conv2D)         (None, 7, 7, 32)     36896       activation_353[0][0]             \n","__________________________________________________________________________________________________\n","dropout_353 (Dropout)           (None, 7, 7, 32)     0           conv_layer_114[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_147 (Concatenate)   (None, 7, 7, 416)    0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","                                                                 dropout_335[0][0]                \n","                                                                 dropout_337[0][0]                \n","                                                                 dropout_339[0][0]                \n","                                                                 dropout_341[0][0]                \n","                                                                 dropout_343[0][0]                \n","                                                                 dropout_345[0][0]                \n","                                                                 dropout_347[0][0]                \n","                                                                 dropout_349[0][0]                \n","                                                                 dropout_351[0][0]                \n","                                                                 dropout_353[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_115 (BatchNormalizatio (None, 7, 7, 416)    1664        concatenate_147[0][0]            \n","__________________________________________________________________________________________________\n","activation_354 (Activation)     (None, 7, 7, 416)    0           bn_layer_115[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_115 (Conv2D)         (None, 7, 7, 128)    53376       activation_354[0][0]             \n","__________________________________________________________________________________________________\n","dropout_354 (Dropout)           (None, 7, 7, 128)    0           conv_layer_115[0][0]             \n","__________________________________________________________________________________________________\n","bn_layer_116 (BatchNormalizatio (None, 7, 7, 128)    512         dropout_354[0][0]                \n","__________________________________________________________________________________________________\n","activation_355 (Activation)     (None, 7, 7, 128)    0           bn_layer_116[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_116 (Conv2D)         (None, 7, 7, 32)     36896       activation_355[0][0]             \n","__________________________________________________________________________________________________\n","dropout_355 (Dropout)           (None, 7, 7, 32)     0           conv_layer_116[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_148 (Concatenate)   (None, 7, 7, 448)    0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","                                                                 dropout_335[0][0]                \n","                                                                 dropout_337[0][0]                \n","                                                                 dropout_339[0][0]                \n","                                                                 dropout_341[0][0]                \n","                                                                 dropout_343[0][0]                \n","                                                                 dropout_345[0][0]                \n","                                                                 dropout_347[0][0]                \n","                                                                 dropout_349[0][0]                \n","                                                                 dropout_351[0][0]                \n","                                                                 dropout_353[0][0]                \n","                                                                 dropout_355[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_117 (BatchNormalizatio (None, 7, 7, 448)    1792        concatenate_148[0][0]            \n","__________________________________________________________________________________________________\n","activation_356 (Activation)     (None, 7, 7, 448)    0           bn_layer_117[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_117 (Conv2D)         (None, 7, 7, 128)    57472       activation_356[0][0]             \n","__________________________________________________________________________________________________\n","dropout_356 (Dropout)           (None, 7, 7, 128)    0           conv_layer_117[0][0]             \n","__________________________________________________________________________________________________\n","bn_layer_118 (BatchNormalizatio (None, 7, 7, 128)    512         dropout_356[0][0]                \n","__________________________________________________________________________________________________\n","activation_357 (Activation)     (None, 7, 7, 128)    0           bn_layer_118[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_118 (Conv2D)         (None, 7, 7, 32)     36896       activation_357[0][0]             \n","__________________________________________________________________________________________________\n","dropout_357 (Dropout)           (None, 7, 7, 32)     0           conv_layer_118[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_149 (Concatenate)   (None, 7, 7, 480)    0           dropout_329[0][0]                \n","                                                                 dropout_331[0][0]                \n","                                                                 dropout_333[0][0]                \n","                                                                 dropout_335[0][0]                \n","                                                                 dropout_337[0][0]                \n","                                                                 dropout_339[0][0]                \n","                                                                 dropout_341[0][0]                \n","                                                                 dropout_343[0][0]                \n","                                                                 dropout_345[0][0]                \n","                                                                 dropout_347[0][0]                \n","                                                                 dropout_349[0][0]                \n","                                                                 dropout_351[0][0]                \n","                                                                 dropout_353[0][0]                \n","                                                                 dropout_355[0][0]                \n","                                                                 dropout_357[0][0]                \n","__________________________________________________________________________________________________\n","bn_layer_119 (BatchNormalizatio (None, 7, 7, 480)    1920        concatenate_149[0][0]            \n","__________________________________________________________________________________________________\n","activation_358 (Activation)     (None, 7, 7, 480)    0           bn_layer_119[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_119 (Conv2D)         (None, 7, 7, 128)    61568       activation_358[0][0]             \n","__________________________________________________________________________________________________\n","dropout_358 (Dropout)           (None, 7, 7, 128)    0           conv_layer_119[0][0]             \n","__________________________________________________________________________________________________\n","bn_layer_120 (BatchNormalizatio (None, 7, 7, 128)    512         dropout_358[0][0]                \n","__________________________________________________________________________________________________\n","activation_359 (Activation)     (None, 7, 7, 128)    0           bn_layer_120[0][0]               \n","__________________________________________________________________________________________________\n","conv_layer_120 (Conv2D)         (None, 7, 7, 32)     36896       activation_359[0][0]             \n","__________________________________________________________________________________________________\n","dropout_359 (Dropout)           (None, 7, 7, 32)     0           conv_layer_120[0][0]             \n","__________________________________________________________________________________________________\n","global_average_pooling2d_2 (Glo (None, 32)           0           dropout_359[0][0]                \n","__________________________________________________________________________________________________\n","fc_layer_121 (Dense)            (None, 4)            132         global_average_pooling2d_2[0][0] \n","==================================================================================================\n","Total params: 4,226,224\n","Trainable params: 4,180,330\n","Non-trainable params: 45,894\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TLsDdKHEcNS","executionInfo":{"status":"ok","timestamp":1626273597022,"user_tz":-330,"elapsed":1273,"user":{"displayName":"Pranab Nandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGLcljhGoE0GLEMDmePj-4a2kCmrEAFJ1MRjpqqQ=s64","userId":"14510125254852299567"}},"outputId":"1898d255-8489-4c76-c941-696bc668e630"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vpl9nF7hJLng","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626273600817,"user_tz":-330,"elapsed":508,"user":{"displayName":"Pranab Nandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGLcljhGoE0GLEMDmePj-4a2kCmrEAFJ1MRjpqqQ=s64","userId":"14510125254852299567"}},"outputId":"21ec1bf6-f8c1-4d1d-b6ed-acab98ecd054"},"source":[" # we need to mention from which directory images will come from\n","train_generator = train_datagen.flow_from_directory(  \n","        '/content/drive/MyDrive/Datasets/Datasets2/Train',\n","        target_size=(224,224),\n","        batch_size=32,\n","        class_mode='categorical')     \n","# categorical means one-hot encoded ytrue values i.e. it alphabetically classifies the different classes and gives them a unique number( 0 for benign, 1 for insitu, 2 for invasive, 3 for normal)\n","\n","validation_generator = val_datagen.flow_from_directory(\n","        '/content/drive/MyDrive/Datasets/Datasets2/Validation',\n","        target_size=(224, 224),\n","        batch_size=32,\n","        class_mode='categorical')\n","test_generator=test_datagen.flow_from_directory(\n","        '/content/drive/MyDrive/Datasets/Datasets2/Test',\n","        target_size=(224,224), \n","        batch_size=32,\n","        class_mode='categorical')\n","\n","print(train_generator.class_indices) # print out the class names along with their unique nos.\n","print(test_generator.class_indices)\n","print(validation_generator.class_indices)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Found 280 images belonging to 1 classes.\n","Found 0 images belonging to 0 classes.\n","Found 280 images belonging to 1 classes.\n","{'Normal': 0}\n","{'Normal': 0}\n","{}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G0p0fdE8xEl2"},"source":["history=model.fit_generator(train_generator, epochs =25,steps_per_epoch=2153,validation_data=validation_generator, validation_steps=175)  # steps_per_epoch = no of batches in the training set = 68880/32 = 2153"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_s7o2svGcB5_","executionInfo":{"status":"ok","timestamp":1626275480101,"user_tz":-330,"elapsed":97790,"user":{"displayName":"Pranab Nandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGLcljhGoE0GLEMDmePj-4a2kCmrEAFJ1MRjpqqQ=s64","userId":"14510125254852299567"}},"outputId":"1945b9af-924d-4774-de9a-95c67fca2edd"},"source":["model.save('/content/drive/MyDrive/Datasets/Datasets2/my_densenet25_with_dropout_new_data')\n","save_history(history.history,'history_densenet25_with_dropout_new_data')\n","#print(history_files[i])"],"execution_count":25,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/Datasets/Datasets2/my_densenet25_with_dropout_new_data/assets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RwjKQ-RikP6l"},"source":["# Prediction phase\n","preds = model.evaluate_generator(train_generator, steps=2153) # preds is an array\n","print (\"train Loss = \" + str(preds[0]))  # preds[0] = loss\n","print (\"train Accuracy = \" + str(preds[1]))  #preds[1] = accuracy\n","preds = model.evaluate_generator(validation_generator, steps=175)\n","print (\"validation Loss = \" + str(preds[0]))\n","print (\"validation Accuracy = \" + str(preds[1]))\n","preds = model.evaluate_generator(test_generator, steps=175)\n","print (\"test Loss = \" + str(preds[0]))\n","print (\"Test Accuracy = \" + str(preds[1]))\n","#model=load_model(model_files[i])\n","    #print(model_files[i])   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mxexLsVyBV5"},"source":["# summarize history for model acuuracy\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()          \n","###\n","\n","print(\"DONE\")"],"execution_count":null,"outputs":[]}]}